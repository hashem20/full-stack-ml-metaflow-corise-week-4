{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiplayer Metaflow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sharing\n",
    "\n",
    "Data scientist's on the same Metaflow deployment have read access to each other's Metaflow results. \n",
    "This is useful in a project because you can make incremental progress on each other results, without reinventing the wheel.\n",
    "You can also compare approaches, results, and split work in a seamless way.\n",
    "\n",
    "Two concepts and sharing features that you should understand to benefit most from Metaflow in a team setting, are namespaces and projects."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Namespaces\n",
    "\n",
    "[Namespaces](https://docs.metaflow.org/scaling/tagging#namespaces) help you to keep results organized. \n",
    "A flow runs in a namespace, and the Metaflow Client API retrieves results for you based on the active namespace.\n",
    "Namespaces are not about security or access control, but for organizing results by the users who produce and analyze them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metaflow import namespace, Metaflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Flow('RF_Flow_cloud'),\n",
       " Flow('Branch_Flow_Cloud'),\n",
       " Flow('Branch_Cloud_Step'),\n",
       " Flow('Branch_Cloud_Flow'),\n",
       " Flow('DivideByZeroFlow'),\n",
       " Flow('RetryFlow'),\n",
       " Flow('TimeoutFlow'),\n",
       " Flow('CatchDivideByZeroFlow'),\n",
       " Flow('TaxiFarePrediction')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "namespace('user:sandbox')\n",
    "Metaflow().flows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Flow('RF_Flow_cloud'),\n",
       " Flow('Branch_Flow_Cloud'),\n",
       " Flow('Branch_Cloud_Step'),\n",
       " Flow('Branch_Cloud_Flow'),\n",
       " Flow('DivideByZeroFlow'),\n",
       " Flow('RetryFlow'),\n",
       " Flow('TimeoutFlow'),\n",
       " Flow('CatchDivideByZeroFlow'),\n",
       " Flow('TaxiFarePrediction')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Expect: the same result in this global (None) namespace as the user:sandbox namespace, \n",
    "    # because your sandbox user is the only user on this Metaflow deployment.\n",
    "namespace(None)\n",
    "Metaflow().flows"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The production namespace\n",
    "There is a special namespace designated production. Production namespaces are important for a variety of reasons. For example, it helps you add authorization keys to the process of deploying to a valuable Flow's production namespace. \n",
    "\n",
    "To get started in production, find your `TaxiFarePrediction` Flow from the week 3 project and run this command with the file path changed to wherever you place the flow in your week 4 workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.10.6+ob(v1)\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mTaxiFarePrediction\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:sandbox\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m2023-11-12 08:11:44.794 \u001b[0m\u001b[22mCreating local datastore in current directory (/home/workspace/workspaces/full-stack-ml-metaflow-corise-week-4/notebooks/.metaflow)\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[1mDeploying \u001b[0m\u001b[31m\u001b[1mtaxifareprediction\u001b[0m\u001b[1m to Argo Workflows...\u001b[K\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[22m\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22mThe namespace of this production flow is\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[22m    production:taxifareprediction-0-ouyj\u001b[K\u001b[0m\u001b[32m\u001b[22m\u001b[0m\n",
      "\u001b[22mTo analyze results of this production flow add this line in your notebooks:\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[22m    namespace(\"production:taxifareprediction-0-ouyj\")\u001b[K\u001b[0m\u001b[32m\u001b[22m\u001b[0m\n",
      "\u001b[22mIf you want to authorize other people to deploy new versions of this flow to Argo Workflows, they need to call\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[22m    argo-workflows create --authorize taxifareprediction-0-ouyj\u001b[K\u001b[0m\u001b[32m\u001b[22m\u001b[0m\n",
      "\u001b[22mwhen deploying this flow to Argo Workflows for the first time.\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22mSee \"Organizing Results\" at https://docs.metaflow.org/ for more information about production tokens.\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22m\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22mBootstrapping virtual environment(s) ...\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[1m    Micromamba ran into an error while setting up environment\u001b[0m\u001b[22m:\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22m    command '/tmp/micromamba/bin/micromamba create --yes --quiet --dry-run --no-extra-safety-checks --repodata-ttl=86400 --retry-clean-cache --prefix=/tmp/tmpg973zx1x/prefix --channel=conda-forge requests==>=2.21.0 boto3==>=1.14.0 pandas==1.4.2 pyarrow==11.0.0 numpy==1.21.2 scikit-learn==1.1.2 python==3.10.12' returned error (1)\n",
      "    package numpy-1.21.2-py37h31617e3_0 requires python_abi 3.7.\u001b[0m\u001b[31m\u001b[1m \u001b[0m\u001b[22m_cp37m, but none of the providers can be installed\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22m\u001b[K\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Watch the file path if you run in the terminal! It may be easiest to do `cd ./notebooks`, if you want to run the commands as is from the terminal.\n",
    "# If you run this cell from the notebook, you should be able to use the path as is.\n",
    "\n",
    "# This will take a minute or two the first time it has to build the conda environment.\n",
    "# Find the namespace this flow is deployed in. Is it production? üßê\n",
    "\n",
    "! python ../flows/cloud/event_triggered_linear_regression_solo.py --environment=conda argo-workflows create"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the output, you will see a line like `namespace(\"user:sandbox\")` or `namespace(\"production:taxifareprediction-0-ouyj\")`. \n",
    "Copy that line, paste it in the first line of the next cell and run it. Then "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'production:taxifareprediction-0-ouyj'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "namespace(\"production:taxifareprediction-0-ouyj\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL: https://argo-pw-323314244.outerbounds.dev and click on the second top left tab 'Workflow Templates'. Then come back here and trigger the flow.\n"
     ]
    }
   ],
   "source": [
    "# run this cell to print your Argo URL\n",
    "import json\n",
    "res = json.load(open(\"/home/workspace/.metaflowconfig/config.json\"))\n",
    "print(\"Go to this URL:\", res['SANDBOX_VSCODE_URL'].replace('vs', 'argo'), \"and click on the second top left tab 'Workflow Templates'. Then come back here and trigger the flow.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.10.6+ob(v1)\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mTaxiFarePrediction\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:sandbox\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[1mWorkflow \u001b[0m\u001b[31m\u001b[1mtaxifareprediction\u001b[0m\u001b[1m triggered on Argo Workflows (run-id \u001b[0m\u001b[31m\u001b[1margo-taxifareprediction-bkgkx\u001b[0m\u001b[1m).\u001b[K\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[1mSee the run in the UI at https://ui-pw-323314244.outerbounds.dev/TaxiFarePrediction/argo-taxifareprediction-bkgkx\u001b[K\u001b[0m\u001b[1m\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! python ../flows/cloud/event_triggered_linear_regression_solo.py --environment=conda argo-workflows trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Flow('TaxiFarePrediction')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell will return an empty list for a minute or two after Argo UI shows the flow running.\n",
    "Metaflow().flows\n",
    "# Do you see a different set of flows than what you saw above with the global or user namespace. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Projects\n",
    "The [`@project decorator`](https://docs.metaflow.org/production/coordinating-larger-metaflow-projects) is for production use cases. \n",
    "\n",
    "It makes available three classes of namespaces that will affect the behavior of a production deployment:\n",
    "1. `user` is the default. It will deploy to a user-specific, private namespace. Use it for testing production deployments.\n",
    "2. `test` denotes custom branches that can be shared amongst multiple users. Use it for deploying experimental versions that can run in parallel with production. Deploy custom branches with `--branch foo`.\n",
    "3. `prod` denotes the global production namespace. Use it for deploying the official production version of the project. Deploy to production with `--production`. For multiple production variants, deploy custom branches with `--production --branch foo`.\n",
    "\n",
    "You don't need to remember these, but they are useful to revisit once you have thought more about the requirements of your ML project.\n",
    "For example, later in this week you will consider how to deploy multiple production variants to score a champion/challenger model on production traffic.\n",
    "\n",
    "### Motivation\n",
    "Consider the situation after you deploy `TaxiFarePrediction` to Argo that is running in production. \n",
    "The next time you deploy `TaxiFarePrediction` by running the same command you just did a few cells ago,\n",
    "```sh\n",
    "python ../flows/cloud/event_triggered_linear_regression.py --environment=conda argo-workflows create\n",
    "```\n",
    "it will overwrite the production `TaxiFarePrediction` flow. Clearly, we want more optionality to run experiments.\n",
    "\n",
    "What do you do when the workflow starts performing well, and multiple people want to test their own production deployments without interfering with yours; or if, as a single developer, you want to experiment with multiple independent deployments of your workflow? How do you create a new workflow without overwriting the existing one? "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going to --production\n",
    "\n",
    "Metaflow's `@project` decorator makes it easy to specifiy the production namespace. You can use this to deploy workflows in different namespaces, and specify a dedicated production branch that is not for anything experimental."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.10.6+ob(v1)\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mTaxiFarePrediction\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:sandbox\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mProject: \u001b[0m\u001b[32m\u001b[1mfullstack\u001b[0m\u001b[35m\u001b[22m, Branch: \u001b[0m\u001b[32m\u001b[1mprod\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[1mDeploying \u001b[0m\u001b[31m\u001b[1mfullstack.prod.taxifareprediction\u001b[0m\u001b[1m to Argo Workflows...\u001b[K\u001b[0m\u001b[1m\u001b[0m\n",
      "\u001b[22mIt seems this is the first time you are deploying \u001b[0m\u001b[31m\u001b[1mfullstack.prod.taxifareprediction\u001b[0m\u001b[22m to Argo Workflows.\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22m\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22mA new production token generated.\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22m\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22mThe namespace of this production flow is\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[22m    production:mfprj-a7y3zg2tm4k4wauw-0-simf\u001b[K\u001b[0m\u001b[32m\u001b[22m\u001b[0m\n",
      "\u001b[22mTo analyze results of this production flow add this line in your notebooks:\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[22m    namespace(\"production:mfprj-a7y3zg2tm4k4wauw-0-simf\")\u001b[K\u001b[0m\u001b[32m\u001b[22m\u001b[0m\n",
      "\u001b[22mIf you want to authorize other people to deploy new versions of this flow to Argo Workflows, they need to call\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[22m    argo-workflows create --authorize mfprj-a7y3zg2tm4k4wauw-0-simf\u001b[K\u001b[0m\u001b[32m\u001b[22m\u001b[0m\n",
      "\u001b[22mwhen deploying this flow to Argo Workflows for the first time.\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22mSee \"Organizing Results\" at https://docs.metaflow.org/ for more information about production tokens.\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22m\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22mBootstrapping virtual environment(s) ...\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[1m    Micromamba ran into an error while setting up environment\u001b[0m\u001b[22m:\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22m    command '/tmp/micromamba/bin/micromamba create --yes --quiet --dry-run --no-extra-safety-checks --repodata-ttl=86400 --retry-clean-cache --prefix=/tmp/tmpvrcvd21t/prefix --channel=conda-forge requests==>=2.21.0 boto3==>=1.14.0 pandas==1.4.2 pyarrow==11.0.0 numpy==1.21.2 scikit-learn==1.1.2 python==3.10.12' returned error (1)\n",
      "    package numpy-1.21.2-py37h31617e3_0 requires python_abi 3.7.\u001b[0m\u001b[31m\u001b[1m \u001b[0m\u001b[22m_cp37m, but none of the providers can be installed\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22m\u001b[K\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! python ../flows/cloud/event_triggered_linear_regression.py --environment=conda --production argo-workflows create"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'production:mfprj-a7y3zg2tm4k4wauw-0-simf'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "namespace(\"production:mfprj-a7y3zg2tm4k4wauw-0-simf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[35m\u001b[1mMetaflow 2.10.6+ob(v1)\u001b[0m\u001b[35m\u001b[22m executing \u001b[0m\u001b[31m\u001b[1mTaxiFarePrediction\u001b[0m\u001b[35m\u001b[22m\u001b[0m\u001b[35m\u001b[22m for \u001b[0m\u001b[31m\u001b[1muser:sandbox\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mProject: \u001b[0m\u001b[32m\u001b[1mfullstack\u001b[0m\u001b[35m\u001b[22m, Branch: \u001b[0m\u001b[32m\u001b[1mprod\u001b[0m\u001b[35m\u001b[22m\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[35m\u001b[22mValidating your flow...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    The graph looks good!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[35m\u001b[22mRunning pylint...\u001b[K\u001b[0m\u001b[35m\u001b[22m\u001b[0m\n",
      "\u001b[32m\u001b[1m    Pylint is happy!\u001b[K\u001b[0m\u001b[32m\u001b[1m\u001b[0m\n",
      "\u001b[1m    Argo Workflows error\u001b[0m\u001b[22m:\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22m    The workflow \u001b[0m\u001b[31m\u001b[1mfullstack.prod.taxifareprediction\u001b[0m\u001b[22m doesn't exist on Argo Workflows in namespace \u001b[0m\u001b[31m\u001b[1mjobs-pw-323314244\u001b[0m\u001b[22m. Please deploy your flow first.\u001b[K\u001b[0m\u001b[22m\u001b[0m\n",
      "\u001b[22m\u001b[K\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! python ../flows/cloud/event_triggered_linear_regression.py --environment=conda --production argo-workflows trigger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "full-stack-metaflow-corise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
